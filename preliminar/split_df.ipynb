{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random as rd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random split (housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partitions = 6\n",
    "input_name = 'housing.csv'\n",
    "output_name = lambda i: input_name.split('.')[0]+'_v'+str(i)+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative, to have fancier names (?)\n",
    "#names = [rd.randint(100_000, 999_999) for i in range(n_partitions)]\n",
    "#output_name = lambda i: input_name.split('.')[0]+'_'+str(names[i])+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('original_data/'+input_name)\n",
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_array = [rd.randint(1, n_partitions) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,n_partitions+1):\n",
    "    rows = [k for k in range(n) if random_array[k] == i]\n",
    "    df1 = df.loc[rows,:]\n",
    "    df1.to_csv('processed_data/' + output_name(i), index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hospitals and schools dataframes\n",
    "Hospitals.csv and Public_Schools.csv have a validation date that can be used to generate the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = 'Hospitals.csv'\n",
    "input_name = 'Public_Schools.csv'\n",
    "df = pd.read_csv('original_data/'+input_name)\n",
    "n = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010-02-10T00:00:00.000Z\n",
      "2018-04-17T00:00:00.000Z\n"
     ]
    }
   ],
   "source": [
    "print(min(df.VAL_DATE))\n",
    "print(max(df.VAL_DATE))\n",
    "min_year = int(min(df.VAL_DATE).split(\"-\")[0])\n",
    "max_year = int(max(df.VAL_DATE).split(\"-\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(min_year, max_year+1):\n",
    "    df1 = df.loc[[i for i in range(n) if df.VAL_DATE[i].split(\"-\")[0] == str(year)],]\n",
    "    filename = input_name.split('.')[0] + '-' + str(year) + '.csv'\n",
    "    df1.to_csv('processed_data/'+filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c68f3bdfe64fcce2211b1df2ac4d2f2c54ba562154ace50b52cfbffa4fa15fa0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
